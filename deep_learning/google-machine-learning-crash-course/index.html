<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
      <link rel="shortcut icon" href="../../img/favicon.ico" />
    <title>Google ML Crash Course - Study Notes</title>
    <link rel="stylesheet" href="../../css/theme.css" />
    <link rel="stylesheet" href="../../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Google ML Crash Course";
        var mkdocs_page_input_path = "deep_learning/google-machine-learning-crash-course.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="../.." class="icon icon-home"> Study Notes
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../..">Introduction</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Algorithm</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../algorithm/alg_blog_note/">Alg blog</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../algorithm/algorithms_4th_edition/">Algorithms 4th Edition (unfinished)</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Blockchain</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../blockchain/blockchain/">Blockchain (unfinished)</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">ML/DL/RL</span></p>
              <ul class="current">
                  <li class="toctree-l1 current"><a class="reference internal current" href="./">Google ML Crash Course</a>
    <ul class="current">
    </ul>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">Python机器学习</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../dl_notes/">DL Notes</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../dive_into_deep_learning/">Dive into Deep Learning (TODO)</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Mathematics</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../mathematics/beauty_of_mathematics/">数学之美</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../mathematics/statistics_concepts_and_controversies/">统计学的世界</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Network</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../network/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/">图解网络 (unfinished)</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Psychology</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../psychology/%E4%B8%8E%E4%BC%97%E4%B8%8D%E5%90%8C%E7%9A%84%E5%BF%83%E7%90%86%E5%AD%A6/">与众不同的心理学</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../psychology/%E5%86%B3%E7%AD%96%E4%B8%8E%E5%88%A4%E6%96%AD/">决策与判断</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../psychology/%E6%9A%97%E6%97%B6%E9%97%B4/">暗时间</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../psychology/%E4%BD%A0%E7%9A%84%E7%81%AF%E4%BA%AE%E7%9D%80%E5%90%97/">你的灯亮着吗</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../psychology/%E6%B2%9F%E9%80%9A%E7%9A%84%E8%89%BA%E6%9C%AF/">沟通的艺术</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../psychology/%E5%BD%B1%E5%93%8D%E5%8A%9B/">影响力</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../psychology/%E4%B8%93%E6%B3%A8%E5%8A%9B/">专注力</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Python</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../python/pythonic/">pythonic</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../python/python_tips/">python tips</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../python/python3/">python3</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../python/effective_python/">Effective Python</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../python/data_structure_and_algorithms_in_python/">Data Structures and Algorithms in Python</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Research</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../research/%E5%83%8F%E5%A4%96%E8%A1%8C%E4%B8%80%E6%A0%B7%E6%80%9D%E8%80%83%EF%BC%8C%E5%83%8F%E4%B8%93%E5%AE%B6%E4%B8%80%E6%A0%B7%E5%AE%9E%E8%B7%B5/">像外行一样思考，像专家一样实践</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Startup</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../startup/how_google_works/">How Google Works</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../startup/startup/">How to start a startup</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Tools</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/arch/">Arch Linux</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/neovim/">Neovim</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/practical_vim/">Practical Vim</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/shell/">Shell</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/git/">Git</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/markdown/">Markdown</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/docker/">Docker (unfinished)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../tools/makefile/">跟我一起写Makefile (unfinished)</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Other</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../other/history_of_quantum_physics/">上帝掷骰子吗？量子物理史话</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../other/%E9%AB%98%E6%95%88%E8%83%BD%E4%BA%BA%E5%A3%AB%E7%9A%847%E4%B8%AA%E4%B9%A0%E6%83%AF/">高效能人士的7个习惯</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../other/%E5%BA%95%E5%B1%82%E9%80%BB%E8%BE%91/">底层逻辑</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../other/%E9%AB%98%E6%95%88%E7%A8%8B%E5%BA%8F%E5%91%98%E7%9A%8445%E4%B8%AA%E4%B9%A0%E6%83%AF/">高效程序员的45个习惯</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../other/code/">编码 隐匿在计算机软硬件背后的语言 (unfinished)</a>
                  </li>
                  <li class="toctree-l1"><a class="reference internal" href="../../other/type_system/">Type System</a>
                  </li>
              </ul>
              <p class="caption"><span class="caption-text">Todo</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../../todo/todo/">TODO</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../..">Study Notes</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../.." class="icon icon-home" aria-label="Docs"></a> &raquo;</li>
          <li>ML/DL/RL &raquo;</li>
      <li>Google ML Crash Course</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="table-of-contents">Table of Contents</h1>
<ol>
<li><a href="#orgea58435">Google Machine Learning crash course</a><ol>
<li><a href="#orgdf01523">编程中的一些参数名说明</a></li>
<li><a href="#org4b0e132">泛化、防止过拟合</a></li>
<li><a href="#org9bab7cf">表示法：特征工程</a><ol>
<li><a href="#orgb4674b1">良好特征的特点</a></li>
<li><a href="#org22b505b">数据清理</a></li>
</ol>
</li>
<li><a href="#org4b5da39">特征组合(Feature Cross)</a></li>
<li><a href="#org3c29828">简化正则化(Regularization for Simplicity)</a><ol>
<li><a href="#org5847e37">降低模型的复杂度</a></li>
<li><a href="#org8935182">L2 正则化（L2 权重衰减）</a></li>
</ol>
</li>
<li><a href="#org1e49989">逻辑回归(Logistic Regression)</a><ol>
<li><a href="#org402ca0b">逻辑回归的损失函数是对数损失函数</a></li>
<li><a href="#orgb1a5e45">S 型函数</a></li>
<li><a href="#orgd8bb3c5">逻辑回归中的正则化</a></li>
</ol>
</li>
<li><a href="#org2ee83e7">分类(Classification)</a><ol>
<li><a href="#orga9999a0">选定阈值</a></li>
<li><a href="#orgf7db782">评估指标</a></li>
</ol>
</li>
<li><a href="#orgf50bc4f">稀疏性正则化(Regularization for Sparsity)</a><ol>
<li><a href="#orgfc4c483">L1 正则化</a></li>
<li><a href="#org533eaf4">L1 和 L2 正则化比较</a></li>
</ol>
</li>
<li><a href="#org5629540">神经网络简介</a></li>
<li><a href="#orgbfc053b">训练神经网络</a></li>
<li><a href="#org3a6241c">多类别神经网络 (Multi-Class Neural Networks)</a><ol>
<li><a href="#org3553ebc">一个标签与多个标签</a></li>
</ol>
</li>
<li><a href="#org827f621">嵌套(Embedding)</a></li>
</ol>
</li>
</ol>
<p><a id="orgea58435"></a></p>
<h1 id="google-machine-learning-crash-course">Google Machine Learning crash course</h1>
<p><a href="https://developers.google.cn/machine-learning/crash-course/ml-intro">https://developers.google.cn/machine-learning/crash-course/ml-intro</a></p>
<p><a id="orgdf01523"></a></p>
<h2 id="_1">编程中的一些参数名说明</h2>
<ul>
<li>steps: 训练迭代总次数，一步计算一批样本产生的损失，然后用该值修改模型的权重一次</li>
<li>batch size: 单步的样本数量（随机选择）</li>
<li>total number of trained examples = batch size * steps</li>
<li>periods: 控制报告的粒度。例如 periods=7, steps=70，则每 7 次（或每 10 步）输出一次损失值</li>
<li>number of training examples in each period = batch size * steps / periods</li>
</ul>
<p><a id="org4b0e132"></a></p>
<h2 id="_2">泛化、防止过拟合</h2>
<ul>
<li>模型尽量简单</li>
<li>训练集、验证集（评估训练集的效果）、测试集（再次检查评估结果）</li>
</ul>
<p><a id="org9bab7cf"></a></p>
<h2 id="_3">表示法：特征工程</h2>
<ul>
<li>即从原始数据中提取特征，表示为特征向量（大约花费机器学习 75%的时间）</li>
<li>理想情况下，特征值取到相同范围</li>
<li>分箱技术</li>
<li>映射分类（枚举）值</li>
</ul>
<p>例如颜色特征只包含 3 个可能的值{red, green, blue}
我们可能会将分类特征编码为枚举类型，例如 0 表示 red，1 表示 green，2 表示 blue
<strong>但是！机器学习模型通常将每个分类特征表示为单独的布尔值，颜色可以表示为 3 个单独的布尔值特征：</strong>
x1: 是 red 吗？x2: 是 green 吗？x3: 是 blue 吗？
采用这种方法编码还可以简化某个值可能属于多个分类的情况，例如“非蓝色”对于 red 和 green 来说都是 True</p>
<p><a id="orgb4674b1"></a></p>
<h3 id="_4">良好特征的特点</h3>
<ul>
<li>避免很少使用的离散特征值</li>
</ul>
<p>良好的特征值应该在数据集中出现大约 5 次以上
例如 house<sub>type 特征可能包含大量样本</sub>，但 unique<sub>house</sub><sub>id 每个值只使用一次</sub>，就不适合作为特征</p>
<ul>
<li>最好具有清晰明确的含义</li>
</ul>
<p>例如 house<sub>age</sub>: 27，但如果是 house<sub>age</sub>: 851472000 那就不便于理解了</p>
<ul>
<li>不要将“神奇”的值与实际数据混为一谈</li>
</ul>
<p>假设一个特征具有 0-1 之间的浮点值，例如 quality<sub>rating</sub>: 0.82
不过，如果用户没有输入 quality<sub>rating</sub>，则数据集可能使用如下神奇值来表示不存在该值：quality<sub>rating</sub>: -1
<strong>为了解决遮盖问题，需要将该特征转换为 2 个特征：</strong>
一个特征只存储质量评分，不含神奇值；一个特征存布尔值，表示是否提供了 quality<sub>rating</sub></p>
<ul>
<li>考虑上游不稳定性</li>
</ul>
<p>特征的定义不应该随时间发生变化，例如 city<sub>id</sub>: "br/sao<sub>paulo</sub>"，但 inferred<sub>city</sub><sub>cluster</sub>: "219"在未来运行其他模型时可能轻易发生变化</p>
<p><a id="org22b505b"></a></p>
<h3 id="_5">数据清理</h3>
<ul>
<li>缩放特征值</li>
</ul>
<p>将多个特征都 scale 到[0,1]或[-1,1]
可以帮助梯度下降法更快收敛
可以避免 NaN 错误
可以帮助模型为每个特征确定合适的权重，如果没有进行特征缩放，模型会对范围较大的特征投入过多精力
如果相差范围不大，不用缩放，例如特征 A 的范围是[-1,1]，特征 B 的范围是[-3,3]</p>
<ul>
<li>处理极端离群值</li>
</ul>
<p>例如 roomsPerPerson，大多值是 1 或 2，但有个别值是 40，可行的方法有： 1.取对数 log 2.将特征值限制到 4，即最大取 4，这样并不意味着忽略大于 4 的值，而是大于 4 的值都取 4</p>
<ul>
<li>分箱</li>
<li>清查</li>
</ul>
<p>检查遗漏数据，移除错误数据</p>
<p><a id="org4b5da39"></a></p>
<h2 id="feature-cross">特征组合(Feature Cross)</h2>
<ul>
<li>即特征交叉，用来表示非线性组合信息</li>
<li>线性学习器如 wowpal-wabit, sofia-ml 或 神经网络</li>
</ul>
<p><a id="org3c29828"></a></p>
<h2 id="regularization-for-simplicity">简化正则化(Regularization for Simplicity)</h2>
<ul>
<li>即不要过于信赖样本</li>
</ul>
<p><a id="org5847e37"></a></p>
<h3 id="_6">降低模型的复杂度</h3>
<ul>
<li>结构风险最小化 minimize: Loss(Data|Model) + complexity(Model)</li>
</ul>
<p>一个是损失项，用于衡量模型与数据的拟合度，另一个是正则化项，用于衡量模型复杂度
旨在减少训练误差，同时平衡复杂度</p>
<p><a id="org8935182"></a></p>
<h3 id="l2-l2">L2 正则化（L2 权重衰减）</h3>
<p>定义模型的复杂度： complexity(Model) = 权重的平方和
<script type="math/tex">L_2 retularization term = ||w||_2^2 = w_1^2 + w_2^2 + ... + w_n^2</script>
</p>
<ul>
<li>首选较小的权重，减少非常大的权重（会对超大权重进行惩罚）</li>
<li>偏离将会产生成本</li>
<li>对于线性模型，首选比较平缓的斜率</li>
<li>
<p>贝叶斯先验概率：权重应该以 0 为中心，权重应该呈正态分布</p>
</li>
<li>
<p>L2 正则化的损失函数</p>
<p>正则化项乘以 lambda，即
<script type="math/tex">L(w, D) + \lambda ||w||_2^2</script>
执行 L2 正则化对模型具有以下影响：</p>
<ul>
<li>使权重值接近于 0（但并非正好为 0）</li>
<li>
<p>使权重的平均值接近于 0，且呈正态分布</p>
</li>
<li>
<p>lambda 值的选择</p>
<p>目标是在简单化和训练数据拟合之间达到适当的平衡</p>
<ul>
<li>增加 lambda 值会增强正则化效果，减小 lambda 值会得出比较平缓的直方图</li>
<li>lambda 值过高，则模型会非常简单，会面临数据欠拟合的风险，模型将无法从训练数据中获得足够的信息来做出有用的预测</li>
<li>lambda 值过低，则模型会比较复杂，会面临数据过拟合的风险，模型将因获得过多训练数据特点方面的信息而无法泛化到新数据</li>
<li><strong>理想的 lambda 值取决于数据</strong> 因此需要手动或自动进行调整</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><a id="org1e49989"></a></p>
<h2 id="logistic-regression">逻辑回归(Logistic Regression)</h2>
<p>逻辑回归会生成一个介于 0 到 1 之间（不包括 0 和 1）的概率值，而不是确切地预测结果是 0 还是 1</p>
<p><a id="org402ca0b"></a></p>
<h3 id="_7">逻辑回归的损失函数是对数损失函数</h3>
<p>（线性回归的损失函数是平方损失）
<script type="math/tex">LogLoss = \sum_{(x,y)\in D} -ylog(y^')-(1-y)log(1-y^')</script>
</p>
<p><a id="orgb1a5e45"></a></p>
<h3 id="s">S 型函数</h3>
<p>输出在 0 和 1 之间
<script type="math/tex">y = 1/(1+e^{-z})</script>
</p>
<p><a id="orgd8bb3c5"></a></p>
<h3 id="_8">逻辑回归中的正则化</h3>
<p>正则化在逻辑回归建模中极其重要。如果没有正则化，逻辑回归的渐近性会不断促使损失在高维度空间内达到 0。
因此，大多数逻辑回归模型会使用以下两个策略之一来降低模型复杂性：</p>
<ul>
<li>L2 正则化</li>
<li>早停法，即，限制训练步数或学习速率。</li>
</ul>
<p><a id="org2ee83e7"></a></p>
<h2 id="classification">分类(Classification)</h2>
<p><a id="orga9999a0"></a></p>
<h3 id="_9">选定阈值</h3>
<p>即将概率输出转换成二元输出的分类结果</p>
<p><a id="orgf7db782"></a></p>
<h3 id="_10">评估指标</h3>
<p>True Positive, False Positive, False Negative, Ture Negative
以“狼来了”举例，“狼来了”是正类别，“没有狼”是负类别</p>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">

<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">类别</th>
<th scope="col" class="org-left">真实情况</th>
<th scope="col" class="org-left">牧童说</th>
<th scope="col" class="org-left">结果</th>
<th scope="col" class="org-left">解释</th>
<th scope="col" class="org-left">预测是否正确</th>
</tr>
</thead>

<tbody>
<tr>
<td class="org-left">TP</td>
<td class="org-left">受到狼的威胁</td>
<td class="org-left">狼来了</td>
<td class="org-left">牧童是个英雄</td>
<td class="org-left">说有狼，狼确实来了</td>
<td class="org-left">正确</td>
</tr>

<tr>
<td class="org-left">FP</td>
<td class="org-left">没受到狼的威胁</td>
<td class="org-left">狼来了</td>
<td class="org-left">村民因牧童说谎而生气</td>
<td class="org-left">说有狼，但狼没来</td>
<td class="org-left">错误</td>
</tr>

<tr>
<td class="org-left">FN</td>
<td class="org-left">受到狼的威胁</td>
<td class="org-left">没有狼</td>
<td class="org-left">狼吃掉了所有人</td>
<td class="org-left">说没狼，但狼来了</td>
<td class="org-left">错误</td>
</tr>

<tr>
<td class="org-left">TN</td>
<td class="org-left">没受到狼的威胁</td>
<td class="org-left">没有狼</td>
<td class="org-left">大家都没事</td>
<td class="org-left">说没狼，狼也没来</td>
<td class="org-left">正确</td>
</tr>
</tbody>
</table>

<ol>
<li>
<p>准确率（欠佳或具有误导性）</p>
<p>Accuracy = (TP+TN) / (TP+TN+FP+FN)
当使用分类不平衡的数据集时（比如正类别标签和负类别标签的数量之间存在明显差异），单单准确率一项并不能反映全面情况</p>
</li>
<li>
<p>精确率和召回率</p>
<p>精确率 Precision = TP/(TP+FP)
召回率 Recall = TP/(TP+FN)
提高分类阈值: 假正例 FP 数量会减少，但假负例 FN 数量会相应地增加。结果，精确率有所提高，而召回率则有所降低
降低分类阈值：假正例数量会增加，而假负例数量会减少。结果这一次，精确率有所降低，而召回率则有所提高</p>
</li>
<li>
<p>ROC(接收者操作特征曲线)和曲线下面积</p>
<p>绘制真正例率（TPR）和假正例率（FPR）
TPR = TP/(TP+FN) 即召回率
FPR = FP/(FP+TN)</p>
</li>
<li>
<p>预测偏差</p>
<p>预测偏差指的是这两个平均值之间的差值，即：
预测偏差 = 预测平均值 - 数据集中相应标签的平均值
造成预测偏差的可能原因包括：</p>
<ul>
<li>特征集不完整</li>
<li>数据集混乱</li>
<li>模型实现流水线中有错误</li>
<li>训练样本有偏差</li>
<li>正则化过强</li>
</ul>
</li>
</ol>
<p><a id="orgf50bc4f"></a></p>
<h2 id="regularization-for-sparsity">稀疏性正则化(Regularization for Sparsity)</h2>
<ul>
<li>特征组合可能会大大增加特征空间</li>
</ul>
<p><a id="orgfc4c483"></a></p>
<h3 id="l1">L1 正则化</h3>
<ul>
<li>会对 L0 权重的范数进行惩罚，非凸优化，NP-hard</li>
<li>L1 正则化比较放松</li>
<li>对绝对值（权重）之和进行惩罚</li>
<li>凸优化问题</li>
<li>和 L2 不同，L1 鼓励稀疏性</li>
<li>使无意义维度的权重正好降至 0</li>
</ul>
<p><a id="org533eaf4"></a></p>
<h3 id="l1-l2">L1 和 L2 正则化比较</h3>
<ol>
<li>
<p>L2 和 L1 采用不同的方式降低权重</p>
<ul>
<li>L2 会降低 权重<sup>2</sup> （平方）</li>
<li>L1 会降低 |权重| （绝对值）</li>
</ul>
</li>
<li>
<p>L2 和 L1 具有不同的导数</p>
<ul>
<li>L2 的导数为 2× 权重</li>
<li>L1 的导数为 k（一个常数，其值与权重无关）</li>
<li>可以将 L2 的导数作用理解为每次移除权重的 x%，即使按每次减去 x%执行数十亿次减法计算，最后的值也不会绝对为 0（即 L2 通常不会使权重变为 0）</li>
<li>可以将 L1 的导数作用理解为每次从权重中减去一个常数，由于减去的是绝对值，L1 在 0 处具有不连续性，这会导致与 0 相交的减法结果变为 0（例如减法使权重从+0.1 变为-0.2，L1 便会将权重设为 0）</li>
<li>L1 正则化——减少所有权重的绝对值——证明对宽度模型非常有效</li>
<li>适用于一维模型</li>
</ul>
</li>
</ol>
<p><a id="org5629540"></a></p>
<h2 id="_11">神经网络简介</h2>
<p><a id="orgbfc053b"></a></p>
<h2 id="_12">训练神经网络</h2>
<p><a id="org3a6241c"></a></p>
<h2 id="multi-class-neural-networks">多类别神经网络 (Multi-Class Neural Networks)</h2>
<ul>
<li>逻辑回归可生成介于 0 和 1.0 之间的小数。例如，某电子邮件分类器的逻辑回归输出值为 0.8，表明电子邮件是垃圾邮件的概率为 80%，不是垃圾邮件的概率为 20%。</li>
<li>Softmax 将这一想法延伸到多类别领域。也就是说，在多类别问题中，Softmax 会为每个类别分配一个用小数表示的概率。</li>
</ul>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">

<colgroup>
<col  class="org-left" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">类别</th>
<th scope="col" class="org-right">概率</th>
</tr>
</thead>

<tbody>
<tr>
<td class="org-left">苹果</td>
<td class="org-right">0.001</td>
</tr>

<tr>
<td class="org-left">熊</td>
<td class="org-right">0.04</td>
</tr>

<tr>
<td class="org-left">糖果</td>
<td class="org-right">0.008</td>
</tr>

<tr>
<td class="org-left">狗</td>
<td class="org-right">0.95</td>
</tr>

<tr>
<td class="org-left">鸡蛋</td>
<td class="org-right">0.001</td>
</tr>
</tbody>
</table>

<ul>
<li>Softmax 层是紧挨着输出层之前的神经网络层。Softmax 层必须和输出层拥有一样的节点数。</li>
<li>Softmax 方程：p(y=j|x) = \frac{e^(w_j^T x+b_j)}{&sum;<sub>k &isin; K</sub> e<sup>(w<sub>k</sub><sup>T</sup> x+b<sub>k</sub>)</sup>}</li>
<li>Softmax 变体：
  完整 Softmax 是我们一直以来讨论的 Softmax；也就是说，Softmax 针对每个可能的类别计算概率。
  候选采样指 Softmax 针对所有正类别标签计算概率，但仅针对负类别标签的随机样本计算概率。例如，如果我们想要确定某个输入图片是小猎犬还是寻血猎犬图片，则不必针对每个非狗狗样本提供概率。</li>
<li>类别数量较少时，完整 Softmax 代价很小，但随着类别数量的增加，它的代价会变得极其高昂。候选采样可以提高处理具有大量类别的问题的效率。</li>
</ul>
<p><a id="org3553ebc"></a></p>
<h3 id="_13">一个标签与多个标签</h3>
<p>Softmax 假设每个样本只是一个类别的成员。但是，一些样本可以同时是多个类别的成员。对于此类示例</p>
<ul>
<li>您不能使用 Softmax</li>
<li>您必须依赖多个逻辑回归</li>
</ul>
<p><a id="org827f621"></a></p>
<h2 id="embedding">嵌套(Embedding)</h2>
<p>嵌套是一种相对低维的空间，您可以将高维矢量映射到这种低维空间里。通过使用嵌套，可以让在大型输入（比如代表字词的稀疏矢量）上进行机器学习变得更加容易。在理想情况下，嵌套可以将语义上相似的不同输入映射到嵌套空间里的邻近处，以此来捕获输入的语义。一个模型学习到的嵌套，也可以被其他模型重用。</p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../../blockchain/blockchain/" class="btn btn-neutral float-left" title="Blockchain (unfinished)"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="btn btn-neutral float-right" title="Python机器学习">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../../blockchain/blockchain/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../Python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme_extra.js" defer></script>
    <script src="../../js/theme.js" defer></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML" defer></script>
      <script src="../../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
